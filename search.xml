<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Kylin查询基本原理]]></title>
    <url>%2F2019%2F04%2F17%2Fquery-on-kylin-cube%2F</url>
    <content type="text"><![CDATA[Kylin的基本架构Apache Kylin™是一个开源的分布式分析引擎，提供Hadoop/Spark之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由eBay Inc. 开发并贡献至开源社区。它能在亚秒内查询巨大的Hive表、Kafka流式数据表、关系型数据库表。 Apache Kylin的基本架构图如下 Kylin的基本查询步骤进行词法分析以一个sql为例： 123456selectWEEK_BEG_DT, sum(PRICE)fromTEST_KYLIN_FACT as fact inner join TEST_CAL_DT as dton fact.CAL_DT = dt.CAL_DT wherefact.CAL_DT &gt;= ‘2017-01-01’ 词法分析的结果为 由select，join和where三部分组成，仅仅一个词法分析的结果是无法被执行的 生成逻辑执行计划上述词法分析随后被转为如下的逻辑计划： from里有两个表，有join关系，先进行join 对表进行project，往上暴露数据 词法中有where条件与group by的情况下，会有对应的filter和aggregate算子操作 在kylin使用apache calcite进行词法分析及逻辑计划的生成，并会进行逻辑执行计划-》物理执行计划的优化。kylin会将图中画圈的部分替换为cube数据，从而达到加速查询的目的。 生成物理执行计划在kylin中对表的join进行替换，即可表示为下图 执行查询]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>kylin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kylin重要jira issue状态]]></title>
    <url>%2F2019%2F04%2F16%2Fkylin-jiras%2F</url>
    <content type="text"><![CDATA[Id 状态 Release 说明 KYLIN-3536 C 2.5.0 使用Kylin的PrepareStatement会cache住OLAPContext，新的segment构建成功后，也不会查最新的结果 KYLIN-3522]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>kylin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kylin的任务调度介绍]]></title>
    <url>%2F2019%2F03%2F30%2FKylin-s-job-scheduler%2F</url>
    <content type="text"><![CDATA[Kylin的任务调度介绍Kylin的任务调度模式采用的是生产者-消费者模式。 Kylin的构建、合并、优化segment任务的入口为EngineFactory的createBatchCubingJob, createBatchMergeJob, createBatchOptimizeJob方法。EngineFactory是一个工厂类，可以根据不同的配置选择不同的cube构建类型（Batch或者Streaming）和不同的cube构建算法（Batch Cube有不同的构建算法）。 Kylin的可执行任务都被表示为一个Executable对象，基本的UML图如下 Executable的核心方法是execute，每个实现类可以定义Job的具体执行逻辑。 1234567891011121314151617public interface Executable &#123; String getId(); String getName(); //定义Job的具体执行逻辑 //参数ExecutableContext Job的上下文 //结果ExecuteResult Job的状态和输出 ExecuteResult execute(ExecutableContext executableContext) throws ExecuteException; //获取Job运行状态 ExecutableState getStatus(); Output getOutput(); boolean isRunnable(); //获取Job的执行参数 Map&lt;String, String&gt; getParams();&#125; 抽象类AbstractExecutable实现了Executable接口，核心是实现了execute方法，为了清晰的定义每个Job的运行状态，AbstractExecutable将execute方法细化为onExecuteStart，doWork，onExecuteError，onExecuteFinished等阶段。其中execute方法修饰符为final，onExecuteStart，onExecuteError，onExecuteFinished方法修饰符为protected，doWork方法修饰符为protected abstract，用于子类根据自己的具体逻辑重写此方法。 execute方法的关键代码如下： 1234567891011121314public final ExecuteResult execute(ExecutableContext executableContext) throws ExecuteException &#123; //Job的状态从Ready 变为 Running onExecuteStart(executableContext); ... //不同的Job在这里实现具体逻辑 result = doWork(executableContext); ... if (exception != null) &#123; //Job的状态从Ready 变为 Error onExecuteError(exception, executableContext); &#125; //Job的状态从Ready 变为 Succeed or Error or Discard onExecuteFinished(result, executableContext); &#125; AbstractExecutable的具体直接实现类主要有ShellExecutable，HadoopShellExecutable，MapReduceExecutable，主要是根据自身的具体逻辑重写了doWork`方法。 ShellExecutable主要用来执行Shell 命令可以直接执行的Job，像计算Hive表行数等Job。 HadoopShellExecutable主要用来执行依赖Hadoop环境且用Shell执行的Job，像建字典，建立HBase表，Bulkload HFile等Job。 MapReduceExecutable主要用来执行MapReduce类型的Job，像计算列基数，计算Cuboid， 生成HFile等Job。 前面提到是CubingJob将构建cube的每一步job串了起来，其实CubingJob继承了DefaultChainedExecutable，DefaultChainedExecutable类继承了 AbstractExecutable类并实现了ChainedExecutable接口。CubingJob 主要是为Job关联了cube和segment的相关信息，串连所有Job的任务都是DefaultChainedExecutable类实现的。 123456public interface ChainedExecutable extends Executable &#123; //获取所有子Job List&lt;? extends AbstractExecutable&gt; getTasks(); //添加子Job void addTask(AbstractExecutable executable);&#125; 之前提到在生成Job的时候，CubingJob通过addTask方法将所有子Job串连了起来。那么DefaultChainedExecutable到底是如何串连起所有子Job呢？关键在其重写的doWork方法里： 123456789101112131415161718protected ExecuteResult doWork(ExecutableContext context) throws ExecuteException &#123; List&lt;? extends Executable&gt; executables = getTasks();//获取所有子Job for (int i = 0; i &lt; executables.size(); ++i) &#123; Executable subTask = executables.get(i); ExecutableState state = subTask.getStatus(); if (state == ExecutableState.RUNNING) &#123; //子Job正在执行，等待它完成 break; &#125; else if (state == ExecutableState.ERROR) &#123; //子Job执行失败，抛出异常 &#125; if (subTask.isRunnable()) &#123; //每个Job在初始化后是Ready状态，所以isRunnable()是True，当子Job是Ready状态时，就开始执行。 return subTask.execute(context); &#125; &#125; return new ExecuteResult(ExecuteResult.State.SUCCEED, null); &#125; DefaultChainedExecutable 也重写了onExecuteFinished方法，来根据所有子Job的状态更新整个Job的最终状态。 Kylin默认通过DefaultScheduler进行任务的调度，其核心逻辑是十分简单的，有两个线程池，一个线程池用来抓取所有Job的状态信息，一个线程池来执行具体的Job。基本的逻辑过程如下： 参考：https://blog.bcmeng.com/post/kylin-job.html]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>kylin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kylin的元数据-任务]]></title>
    <url>%2F2019%2F03%2F30%2FKylin-s-metadata-execute%2F</url>
    <content type="text"><![CDATA[Kyin任务元数据基本介绍在Kylin的元数据基础一文中介绍了kylin元数据的一些源码级基础知识。使用 Kylin生成每执行一个构建或合并任务，都会在Monitor页面生成一个job Kylin使用存于resource store的metadata来实现元数据的持久化保存。 对于任务元数，Kylin使用了2中类型的元数据，分别为execute和execute_output execute：存储与表示任务的执行计划 execute_output：存储与表示任务的执行结果 每个任务仅有一个execute元数据，会有(step_num + 1)个execute_output元数据，如下图所示为一dump下来的某个任务的元数据 execute的基本元数据类为org.apache.kylin.job.dao.ExecutablePO，代码为 1234567891011121314151617181920public class ExecutablePO extends RootPersistentEntity &#123; // 任务名 @JsonProperty("name") private String name; // 子任务列表 @JsonProperty("tasks") private List&lt;ExecutablePO&gt; tasks; // 任务类型 @JsonProperty("type") private String type; // 任务参数 @JsonProperty("params") private Map&lt;String, String&gt; params = Maps.newHashMap(); //....&#125; 生成的json元数据文件示例如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&#123; "uuid": "99b80122-b59b-bbdb-5f22-26d1d9270220", "last_modified": 1555246404591, "version": "2.6.0.20500", "name": "BUILD CUBE - kylin_sales_cube - 20120101000000_20190430185000 - GMT+08:00 2019-04-14 20:53:24", "tasks": [ &#123; "uuid": "99b80122-b59b-bbdb-5f22-26d1d9270220-00", "last_modified": 0, "version": "2.6.0.20500", "name": "Create Intermediate Flat Hive Table", "tasks": null, "type": "org.apache.kylin.source.hive.CreateFlatHiveTableStep", "params": &#123; "HiveInit": "USE default; ", "HiveRedistributeData": "DROP TABLE IF EXISTS kylin_intermediate_kylin_sales_cube_86f98364_1485_001b_8fc5_18ec50930a14; CREATE EXTERNAL TABLE IF NOT EXISTS kylin_intermediate_kylin_sales_cube_86f98364_1485_001b_8fc5_18ec50930a14 ( KYLIN_SALES_TRANS_ID bigint ,KYLIN_SALES_PART_DT date ,KYLIN_SALES_LEAF_CATEG_ID bigint ,KYLIN_SALES_LSTG_SITE_ID int ,KYLIN_CATEGORY_GROUPINGS_META_CATEG_NAME string ,KYLIN_CATEGORY_GROUPINGS_CATEG_LVL2_NAME string ,KYLIN_CATEGORY_GROUPINGS_CATEG_LVL3_NAME string ,KYLIN_SALES_LSTG_FORMAT_NAME string ,KYLIN_SALES_SELLER_ID bigint ,KYLIN_SALES_BUYER_ID bigint ,BUYER_ACCOUNT_ACCOUNT_BUYER_LEVEL int ,SELLER_ACCOUNT_ACCOUNT_SELLER_LEVEL int ,BUYER_ACCOUNT_ACCOUNT_COUNTRY string ,SELLER_ACCOUNT_ACCOUNT_COUNTRY string ,BUYER_COUNTRY_NAME string ,SELLER_COUNTRY_NAME string ,KYLIN_SALES_OPS_USER_ID string ,KYLIN_SALES_OPS_REGION string ,KYLIN_SALES_PRICE decimal(19,4) ) STORED AS SEQUENCEFILE LOCATION 'hdfs://sandbox.hortonworks.com:8020/Users/nichunen/Downloads/template/kylin-99b80122-b59b-bbdb-5f22-26d1d9270220/kylin_intermediate_kylin_sales_cube_86f98364_1485_001b_8fc5_18ec50930a14'; ALTER TABLE kylin_intermediate_kylin_sales_cube_86f98364_1485_001b_8fc5_18ec50930a14 SET TBLPROPERTIES('auto.purge'='true'); INSERT OVERWRITE TABLE `kylin_intermediate_kylin_sales_cube_86f98364_1485_001b_8fc5_18ec50930a14` SELECT `KYLIN_SALES`.`TRANS_ID` as `KYLIN_SALES_TRANS_ID` ,`KYLIN_SALES`.`PART_DT` as `KYLIN_SALES_PART_DT` ,`KYLIN_SALES`.`LEAF_CATEG_ID` as `KYLIN_SALES_LEAF_CATEG_ID` ,`KYLIN_SALES`.`LSTG_SITE_ID` as `KYLIN_SALES_LSTG_SITE_ID` ,`KYLIN_CATEGORY_GROUPINGS`.`META_CATEG_NAME` as `KYLIN_CATEGORY_GROUPINGS_META_CATEG_NAME` ,`KYLIN_CATEGORY_GROUPINGS`.`CATEG_LVL2_NAME` as `KYLIN_CATEGORY_GROUPINGS_CATEG_LVL2_NAME` ,`KYLIN_CATEGORY_GROUPINGS`.`CATEG_LVL3_NAME` as `KYLIN_CATEGORY_GROUPINGS_CATEG_LVL3_NAME` ,`KYLIN_SALES`.`LSTG_FORMAT_NAME` as `KYLIN_SALES_LSTG_FORMAT_NAME` ,`KYLIN_SALES`.`SELLER_ID` as `KYLIN_SALES_SELLER_ID` ,`KYLIN_SALES`.`BUYER_ID` as `KYLIN_SALES_BUYER_ID` ,`BUYER_ACCOUNT`.`ACCOUNT_BUYER_LEVEL` as `BUYER_ACCOUNT_ACCOUNT_BUYER_LEVEL` ,`SELLER_ACCOUNT`.`ACCOUNT_SELLER_LEVEL` as `SELLER_ACCOUNT_ACCOUNT_SELLER_LEVEL` ,`BUYER_ACCOUNT`.`ACCOUNT_COUNTRY` as `BUYER_ACCOUNT_ACCOUNT_COUNTRY` ,`SELLER_ACCOUNT`.`ACCOUNT_COUNTRY` as `SELLER_ACCOUNT_ACCOUNT_COUNTRY` ,`BUYER_COUNTRY`.`NAME` as `BUYER_COUNTRY_NAME` ,`SELLER_COUNTRY`.`NAME` as `SELLER_COUNTRY_NAME` ,`KYLIN_SALES`.`OPS_USER_ID` as `KYLIN_SALES_OPS_USER_ID` ,`KYLIN_SALES`.`OPS_REGION` as `KYLIN_SALES_OPS_REGION` ,`KYLIN_SALES`.`PRICE` as `KYLIN_SALES_PRICE` FROM `DEFAULT`.`KYLIN_SALES` as `KYLIN_SALES` INNER JOIN `DEFAULT`.`KYLIN_CAL_DT` as `KYLIN_CAL_DT` ON `KYLIN_SALES`.`PART_DT` = `KYLIN_CAL_DT`.`CAL_DT` INNER JOIN `DEFAULT`.`KYLIN_CATEGORY_GROUPINGS` as `KYLIN_CATEGORY_GROUPINGS` ON `KYLIN_SALES`.`LEAF_CATEG_ID` = `KYLIN_CATEGORY_GROUPINGS`.`LEAF_CATEG_ID` AND `KYLIN_SALES`.`LSTG_SITE_ID` = `KYLIN_CATEGORY_GROUPINGS`.`SITE_ID` INNER JOIN `DEFAULT`.`KYLIN_ACCOUNT` as `BUYER_ACCOUNT` ON `KYLIN_SALES`.`BUYER_ID` = `BUYER_ACCOUNT`.`ACCOUNT_ID` INNER JOIN `DEFAULT`.`KYLIN_ACCOUNT` as `SELLER_ACCOUNT` ON `KYLIN_SALES`.`SELLER_ID` = `SELLER_ACCOUNT`.`ACCOUNT_ID` INNER JOIN `DEFAULT`.`KYLIN_COUNTRY` as `BUYER_COUNTRY` ON `BUYER_ACCOUNT`.`ACCOUNT_COUNTRY` = `BUYER_COUNTRY`.`COUNTRY` INNER JOIN `DEFAULT`.`KYLIN_COUNTRY` as `SELLER_COUNTRY` ON `SELLER_ACCOUNT`.`ACCOUNT_COUNTRY` = `SELLER_COUNTRY`.`COUNTRY` WHERE 1=1 AND (`KYLIN_SALES`.`PART_DT` &gt;= '2012-01-01' AND `KYLIN_SALES`.`PART_DT` &lt; '2019-04-30') ; ", "cubeName": "kylin_sales_cube" &#125; &#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125; ], "type": "org.apache.kylin.engine.mr.CubingJob", "params": &#123; "submitter": "ADMIN", "envName": "DEV", "segmentId": "86f98364-1485-001b-8fc5-18ec50930a14", "notify_list": "", "projectName": "learn_kylin", "jobType": "BUILD", "cubeName": "kylin_sales_cube", "segmentName": "20120101000000_20190430185000" &#125;&#125; execute_output的基本元数据类为org.apache.kylin.job.dao.ExecutableOutputPO，代码为 1234567891011public class ExecutableOutputPO extends RootPersistentEntity &#123; @JsonProperty("content") private String content; @JsonProperty("status") private String status = "READY"; @JsonProperty("info") private Map&lt;String, String&gt; info = Maps.newHashMap();&#125; 生成的全局任务json元数据文件示例如下： 1234567891011121314&#123; "uuid": "99b80122-b59b-bbdb-5f22-26d1d9270220", "last_modified": 1555246411812, "version": "2.6.0.20500", "content": "org.apache.kylin.job.exception.ExecuteException: java.io.IOException: OS command error exit with return code: 127, error message: /bin/bash: hive: command not foundThe command is: hive -e \"", "status": "ERROR", "info": &#123; "startTime": "1555246411762", "buildInstance": "62641@GggdeMacBook-Pro.local", "endTime": "1555246411811" &#125;&#125; 生成的子任务json元数据文件示例如下： 12345678910111213&#123; "uuid": "99b80122-b59b-bbdb-5f22-26d1d9270220-00", "last_modified": 1555246411809, "version": "2.6.0.20500", "content": "java.io.IOException: OS command error exit with return code: 127, error message: /bin/bash: hive: command not foundThe command is: hive -e \"", "status": "ERROR", "info": &#123; "startTime": "1555246411769", "endTime": "1555246411807" &#125;&#125;]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>kylin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kylin的元数据基础]]></title>
    <url>%2F2019%2F03%2F30%2FKylin-s-metadata-base%2F</url>
    <content type="text"><![CDATA[Apache Kylin元数据基础Apache Kylin的元数据包括 立方体描述（cube description）、立方体实例（cube instance）、项目（project）、模型描述（model description）、作业（job）、表（table）、字典(dictionary)等，参见： Kylin核心概念。在kylin集群中至关重要，假如元数据丢失，kylin集群将无法工作。 Kylin源码定义了ResourceStore这一抽象类来定义，其中定义了各种对元数据增删改查的方法，主要方法如： 1234567891011121314151617// 根据kylinConfig获得对应的ResourceStoreResourceStore getStore(KylinConfig kylinConfig)// 根据目录获取所有元数据路径NavigableSet&lt;String&gt; listResources(String folderPath)// 路径resPath下是否存在元数据boolean exists(String resPath) // 根据路径resPath及序列化器serializer返回对应的元数据&lt;T extends RootPersistentEntity&gt; T getResource(String resPath, Serializer&lt;T&gt; serializer) // 根据路径resPath写入元数据 public &lt;T extends RootPersistentEntity&gt; long putResource(String resPath, T obj, long ts, Serializer&lt;T&gt; serializer) // 删除路径resPath下的元数据void deleteResource(String resPath) ResourceStore类的主要子类继承关系图如下： Kylin支持多种数据源格式，如Hbase、Jdbc等，只要继承ResourceStore类并实现必须的Impl方法即可。 Kylin的所有序列化的元数据都继承自RootPersistentEntity抽象类，该类及其子类都使用了jackson的JsonAutoDetect注解。 例如CubeDesc部分代码如下： 1234567891011121314151617181920212223242526272829@SuppressWarnings(&quot;serial&quot;)@JsonAutoDetect(fieldVisibility = Visibility.NONE, getterVisibility = Visibility.NONE, isGetterVisibility = Visibility.NONE, setterVisibility = Visibility.NONE)public class CubeDesc extends RootPersistentEntity implements IEngineAware &#123; //... @JsonProperty(&quot;name&quot;) private String name; @JsonProperty(&quot;is_draft&quot;) private boolean isDraft; @JsonProperty(&quot;model_name&quot;) private String modelName; @JsonProperty(&quot;description&quot;) private String description; @JsonProperty(&quot;null_string&quot;) private String[] nullStrings; @JsonProperty(&quot;dimensions&quot;) private List&lt;DimensionDesc&gt; dimensions; @JsonProperty(&quot;measures&quot;) private List&lt;MeasureDesc&gt; measures; @JsonProperty(&quot;dictionaries&quot;) @JsonInclude(JsonInclude.Include.NON_NULL) private List&lt;DictionaryDesc&gt; dictionaries; @JsonProperty(&quot;rowkey&quot;) private RowKeyDesc rowkey; @JsonProperty(&quot;hbase_mapping&quot;) private HBaseMappingDesc hbaseMapping; @JsonProperty(&quot;aggregation_groups&quot;) private List&lt;AggregationGroup&gt; aggregationGroups; // ...&#125; 对应在元数据库的json数据如下： 12345678910111213141516&#123; "uuid":"0ef9b7a8-3929-4dff-b59d-2100aadc8dbf", "last_modified":1451468470824, "version":"%default_version%", "name":"kylin_sales_cube", "is_draft":false, "model_name":"kylin_sales_model", "description":"", "null_string":null, "dimensions":[], "measures":[], "rowkey":&#123;&#125;, "hbase_mapping":&#123;&#125;, "aggregation_groups":[], ...&#125;]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>kylin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSI七层模型的通俗理解]]></title>
    <url>%2F2019%2F03%2F12%2Fosi-tcpip%2F</url>
    <content type="text"><![CDATA[OSI七层模型的通俗理解 以你和你女朋友以书信的方式进行通信为例。 物理层：运输工具，比如火车、汽车 数据链路层：相当于货物核对单，表明里面有些什么东西，接受的时候确认一下是否正确（CRC检验） 网络层：相当于邮政局或快递公司地址（IP地址），能正确到达对方 传输层：信封（TCP协议是挂号信，是可靠的；UDP协议是平信，尽力送到对方，不保证一点送到对方） 会话层：相当于邮票，优质邮票寄一封信，相当与一个会话 表示层：你用普通话还是用方言？或者是英语？ 应用层：你可以说你的内容了，可以说是你爱她，也可以说你恨她。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用gogs安装本地git服务(Centos环境)]]></title>
    <url>%2F2019%2F03%2F11%2Fgogs-install%2F</url>
    <content type="text"><![CDATA[使用gogs安装本地git服务(Centos环境)安装数据库Gogs支持MySQL、PostgreSQL、SQLite3、TiDB。安装过程这里不赘述，我们使用的是MySQL。 安装git1yum install -y git 添加git用户（gogs期望用git用户操作）1sudo useradd git 下载并安装根据自己的linux版本在 https://dl.gogs.io/ 下载安装包，linux版本根据uname -a查看 1wget https://dl.gogs.io/0.11.86/gogs_0.11.86_linux_amd64.tar.gz 解压 1tar -zxvf gogs_0.11.86_linux_amd64.tar.gz 进入解压的目录，执行 12cd gogs/./gogs web 打开${ip}:3000页面，出现如下配置页面 配置完数据库、端口、用户信息等 运行gogsControl+C暂停当前gogs进程，后台运行gogs 1nohup ./gogs web &amp; 打开${ip}:3000页面，注册后登陆]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hive 常用命令]]></title>
    <url>%2F2019%2F03%2F10%2Fhive-cli%2F</url>
    <content type="text"><![CDATA[Hive常用命令创建表： 1CREATE TABLE pokes (foo INT, bar STRING); 创建一个新表，结构与其他一样： 1create table new_table like records; 创建分区表： 1create table logs(ts bigint,line string) partitioned by (dt String,country String); 加载分区表数据： 1load data local inpath '/home/Hadoop/input/hive/partitions/file1' into table logs partition (dt='2001-01-01',country='GB'); 展示表中有多少分区： 1show partitions logs; 展示所有表： 1SHOW TABLES; 显示表的结构信息： 1DESCRIBE invites; 更新表的名称： 1ALTER TABLE source RENAME TO target; 添加新一列： 1ALTER TABLE invites ADD COLUMNS (new_col2 INT COMMENT 'a comment'); 添加新的一行： 1INSERT INTO test(name,pwd,createdate) values('name1','pwd1','2017-06-20 14:14:09'); 删除表： 1DROP TABLE records; 删除表中数据，但要保持表的结构定义： 1TRUNCATE TABLE table_name 从本地文件加载数据： 1LOAD DATA LOCAL INPATH '/home/hadoop/input/ncdc/micro-tab/sample.txt' OVERWRITE INTO TABLE records; 显示所有函数： 1show functions; 查看函数用法： 1describe function substr; 内连接： 1SELECT sales., things. FROM sales JOIN things ON (sales.id = things.id); 查看hive为某个查询使用多少个MapReduce作业: 1Explain SELECT sales., things. FROM sales JOIN things ON (sales.id = things.id); 外连接： 1SELECT sales., things. FROM sales LEFT OUTER JOIN things ON (sales.id = things.id); 创建视图： 1CREATE VIEW valid_records AS SELECT * FROM records2 WHERE temperature !=9999; INSERT OVERWRITE： 1INSERT OVERWRITE table tablename1 select a, b, c from tablename2; 参考：https://www.jianshu.com/p/a8e259b973ef]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F06%2F07%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>hello world</category>
      </categories>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
</search>
